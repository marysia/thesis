# Candidates generated by the localization model are saved in a patches-?.pkl.zip format. These zipped pickle files were
# written using protocol 4, which is not supported by Python 2.7, and cannot be loaded. Therefore, this python3 script
# reads in all zipped pickle files and converts them to a format that can be loaded using Python 2.7.
# Note: preferably run this script from command line with sudo, as a permission denied error otherwise occurs for the
# /home/marysia/data folder on Azure.
import glob
import numpy as np
from preprocessing.zippedpickles import load

# collect paths to all patch-?.pkl.zip files.
patch_folder = '/home/marysia/data/thesis/nlst-patches-1.3-3.5-annotated/'
patches = glob.glob(patch_folder + '*.pkl.zip')

def extract_positive_samples():
    """
    Extracts all available positive train and test samples from the zipped pickle files. Returns the amount of
    samples were extracted for the train and test set respectively.

    Returns:
        train_samples: train.shape[0], number of samples in the positive train set.
        test_samples: test.shape[0], number of samples in the positive test set.
    """
    print('Extracting positive samples from %d patches.' % len(patches))
    # initialize lists
    train = []
    test = []

    # loop through all patch-?.pkl.zips and extract positive samples
    for patch_path in patches:
        print(patch_path)
        # loading only loads the keys, therefore takes little time
        unzipped = load(patch_path)

        # load the positive training and test samples
        pos_train = unzipped['train-positive-inputs']
        pos_test = unzipped['test-positive-inputs']

        # append positive training and test samples to list
        train.append(pos_train)
        test.append(pos_test)

    # concatenate all samples (assuming same size)
    train = np.concatenate(train)
    test = np.concatenate(test)

    # save
    np.savez('/home/marysia/data/thesis/patches/positive_train_patches.npz', data=train)
    np.savez('/home/marysia/data/thesis/patches/positive_test_patches.npz', data=test)

    return train.shape[0], test.shape[0]

def extract_negative_samples(scope, samples):
    """
    Extracts a given number (samples) of negative samples from the zipped pickles, for the given scope (train or test).
    It does this by opening and reading in the zipped pickle patch while the amount of samples is not yet met, and
    concatenating the candidates to a list of candidates.

    Args:
        scope: str, train or test.
        samples: int, the amount of samples that will be extracted from the zipped pickles.
    """
    print('Extracting %d negative samples for the %s set.' % (samples, scope))
    # initialize lists
    li = []

    # initialize stop criteria
    limit = False
    i = 0
    total = 0

    # loop through while limit is not matched and still patch paths left
    while not limit and i < len(patches):
        # unzip and load negative inputs
        unzipped = load(patches[i])
        neg_inputs = unzipped[scope+'-negative-inputs']
        i += 1

        # add carelessly when adding will not exceed the sample limit
        if (total + neg_inputs.shape[0]) < samples:
            li.append(neg_inputs)
            total += neg_inputs.shape[0]
        # add portion of the candidates if adding all would exceed the sample limit
        else:
            to_add = samples - total
            li.append(neg_inputs[:to_add])
            total += to_add
            limit = True

    # save
    data = np.concatenate(li)
    np.savez('/home/marysia/data/thesis/patches/negative_'+scope+'_patches.npz', data=data)

# execute all steps
train_samples, test_samples = extract_positive_samples()
extract_negative_samples('train', train_samples)
extract_negative_samples('test', test_samples)
